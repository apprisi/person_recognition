{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import loadtxt\n",
    "import cv2\n",
    "\n",
    "# caffe layers\n",
    "caffe_root = '/users/vijay.kumar/caffe/'\n",
    "sys.path.insert(0, caffe_root + 'python')\n",
    "sys.path.insert(0, '/users/vijay.kumar/tools/liblinear-2.1/python')\n",
    "\n",
    "import caffe\n",
    "from caffe import layers as L\n",
    "from liblinearutil import *\n",
    "from utils import *\n",
    "\n",
    "# enable gpu\n",
    "caffe.set_mode_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "annot_dir = '../data/soccer/annot/'\n",
    "image_dir = '../data/soccer/frames/'\n",
    "train_split_file = '../data/soccer/train_split.txt'\n",
    "test_split_file = '../data/soccer/test_split.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = read_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initilaze caffe transformer\n",
    "transformer = define_transformer()\n",
    "\n",
    "# load pose nets and the pose estimator\n",
    "nets, pose_net = load_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import PIL.Image\n",
    "from cStringIO import StringIO\n",
    "import IPython.display\n",
    "\n",
    "def showarray(a, fmt='png'):\n",
    "    a = np.uint8(a)\n",
    "    f = StringIO()\n",
    "    PIL.Image.fromarray(a).save(f, fmt)\n",
    "    IPython.display.display(IPython.display.Image(data=f.getvalue()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_files(clips):\n",
    "    annot_data = {}\n",
    "    for clip_id in range(len(clips)):\n",
    "        clip_no = clips[clip_id]\n",
    "        clip_label_fn = annot_dir + 'clip' + str(clip_no) + '.txt'\n",
    "        with open(clip_label_fn) as f:\n",
    "            clip_raw_data = f.readlines()\n",
    "\n",
    "        clip_data = []\n",
    "        for _data in clip_raw_data:\n",
    "            _data = _data.strip().split(' ')\n",
    "            \n",
    "            # skip errorenous annotations\n",
    "            if len(_data) < 10:\n",
    "                continue    \n",
    "                \n",
    "            # skip boxes outside the frame.\n",
    "            if _data[6] == '1':\n",
    "                continue\n",
    "                \n",
    "            _data[9] = _data[9].replace(\"\\\"\",'')\n",
    "            if _data[9] in label_names:\n",
    "                _data[9] = label_names[_data[9]] \n",
    "                clip_data.append(np.concatenate((np.array(_data[0:10]),np.array([clip_no])),axis=0).tolist())\n",
    "        annot_data[clip_id] = np.array(clip_data).astype(int)                 \n",
    "\n",
    "    # rename the track-id in clips    \n",
    "    max_track_id = 0    \n",
    "    for clip_id in range(len(clips)): #keep the first clip as it is\n",
    "        annot_data[clip_id][:,0] = max_track_id + annot_data[clip_id][:,0]\n",
    "        max_track_id = np.max(annot_data[clip_id][:,0]) + 1\n",
    "\n",
    "    # concatenate the clips    \n",
    "    annot_data_final = annot_data[0]\n",
    "    for clip_id in range(1, len(clips)):\n",
    "        annot_data_final = np.concatenate((annot_data_final, annot_data[clip_id]), axis=0)     \n",
    "        \n",
    "    return annot_data_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clip_nos = [1, 2, 3, 4, 5, 7, 8, 11, 14, 16, 17, 20, 23, 28, 29, 31, 34, 35, 36, \n",
    "            37, 38, 39, 40, 43, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 62]\n",
    "\n",
    "train_clips = loadtxt(train_split_file).astype(int)\n",
    "test_clips = loadtxt(test_split_file).astype(int)\n",
    "\n",
    "label_names = {'Manuel_Neuer':0, 'Benedikt_Hoewedes':1, 'Mats_Hummels':2, 'Schweinsteiger':3, 'Mesut_Oezil':4, \n",
    "           'Miroslav_Klose':5, 'Thomas_Mueller':6, 'Phillip_Lahm':7, 'Toni_Kroos':8, 'Jerome_Boateng':9, \n",
    "           'Christoph_Kramer':10, 'Per_Mertesacker':11, 'Mario_Gotze':12, 'Andre_Schurrle':13, 'Sergio_Romero':14, \n",
    "           'Ezequiel_Garay':15, 'Pabli_Zabaleta':16, 'Lucas_Biglia':17, 'Enzo_Perez':18, 'Gonzalo_Huguain':19, \n",
    "           'Lionel_Messi':20, 'Javier_MAscherano':21, 'Martin_Demichelis':22, 'Marcos_Rojo':23, 'Ezequiel_Lavezzi':24, \n",
    "           'Fernando_Gago':25, 'Sergio_Aguero':26, 'Rodrigo_Palacio':27, 'Referee':28,\n",
    "          }\n",
    "\n",
    "train_annot = process_files(train_clips)\n",
    "test_annot = process_files(test_clips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'Number of training samples:', train_annot.shape[0]\n",
    "print 'Number of testing samples:', test_annot.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_regions(image, box):\n",
    "    \n",
    "    [x1, y1, x2, y2] = box[1], box[2], box[3], box[4]    \n",
    "    img_h, img_w, img_c = image.shape\n",
    "\n",
    "    body = image[max(0, y1): min(img_h, y2),  max(0, x1): min(img_w, x2), :]\n",
    "    body_h = y2 - y1\n",
    "    h_x1, h_y1, h_x2, u_x1, u_y1, u_x2 = x1, y1, x2, x1, y1, x2    \n",
    "    h_y2 = int(h_y1 + 0.4*body_h)\n",
    "    u_y2 = int(h_y1 + 0.7*body_h)\n",
    "        \n",
    "    head = image[max(0, h_y1): min(img_h, h_y2),  max(0, h_x1): min(img_w, h_x2), :]        \n",
    "    ub = image[max(0, u_y1): min(img_h, u_y2),  max(0, u_x1): min(img_w, u_x2), :]\n",
    "    \n",
    "    return head, ub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# extract training features\n",
    "num_models = len(nets)\n",
    "num_train = train_annot.shape[0]\n",
    "train_features = np.zeros((num_train, num_models, params['FEATSIZE']))\n",
    "train_labels = np.zeros((num_train,1)) \n",
    "\n",
    "for i in range(num_train):        \n",
    "    \n",
    "    box_data = train_annot[i]    \n",
    "    clip_no, frame_no, box_label = box_data[-1], box_data[5], box_data[9]    \n",
    "    img_name = image_dir + str(clip_no) + '/' + str(frame_no) + '.jpg'\n",
    "    entire_image = cv2.imread(img_name)      \n",
    "    head, upper_body = extract_regions(entire_image, box_data)  \n",
    "    train_features[i] = get_pose_features(transformer, nets, head, upper_body, num_models, params['FEATSIZE'])  \n",
    "    train_labels[i] = int(box_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Classifier training\n",
    "classifiers = train_linear_classifiers(train_features, np.squeeze(train_labels), num_models, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_test = test_annot.shape[0]\n",
    "test_labels = []\n",
    "test_tracks = []\n",
    "pred_scores = []\n",
    "for i in range(num_test):            \n",
    "    box_data = test_annot[i]    \n",
    "    clip_no, frame_no, box_label, tid = box_data[-1], box_data[5], box_data[9], box_data[0]\n",
    "    img_name = image_dir + str(clip_no) + '/' + str(frame_no) + '.jpg'\n",
    "    entire_image = cv2.imread(img_name)      \n",
    "    head, upper_body = extract_regions(entire_image, box_data)        \n",
    "    test_feature = get_pose_features(transformer, nets, head, upper_body, num_models, params['FEATSIZE'])                    \n",
    "    pose_weights = get_pose_weights(transformer, pose_net, upper_body)                                        \n",
    "    pred_sample_sc = pose_aware_identity_prediction_(classifiers, test_feature, np.array([box_label]), pose_weights,  params, num_models)                       \n",
    "    pred_scores.append(pred_sample_sc[0]) \n",
    "    test_tracks.append(tid)    \n",
    "    test_labels.append(int(box_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# obtain predicted labels\n",
    "model_labels = classifiers[0][0].get_labels()\n",
    "pred_labels = [model_labels[np.argmax(ps)] for ps in pred_scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "overall_acc = 100*np.mean(np.squeeze(np.array(test_labels)) == np.squeeze(np.array(pred_labels)))\n",
    "print 'overall accuracy/Known subject accuracy:', overall_acc\n",
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "correct_per_player = {}\n",
    "num_examples_per_player = {}\n",
    "for i in range(len(test_labels)):\n",
    "    \n",
    "        # initiliaze dict\n",
    "        if test_labels[i] not in num_examples_per_player:\n",
    "            num_examples_per_player[test_labels[i]] = 0  \n",
    "            correct_per_player[test_labels[i]] = 0                \n",
    "            \n",
    "        num_examples_per_player[test_labels[i]] = num_examples_per_player[test_labels[i]] + 1    \n",
    "        \n",
    "        if test_labels[i]==pred_labels[i]:\n",
    "            correct_per_player[test_labels[i]] = correct_per_player[test_labels[i]] + 1\n",
    "        \n",
    "for tl in correct_per_player:\n",
    "    print int(tl), correct_per_player[tl], num_examples_per_player[tl],100*correct_per_player[tl]/float(num_examples_per_player[tl])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
